{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a06efcf9",
   "metadata": {},
   "source": [
    "# Unsupervised examples (Clustering + Reduction)\n",
    "\n",
    "This notebook provides interactive examples to run and debug the project's pipelines and to execute quick ad-hoc unsupervised analyses (KMeans, DBSCAN, Hierarchical, PCA, t-SNE). It is written to run from the project root. Adjust paths if you open it from a different folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b03ab125",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 15) (4028283207.py, line 15)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mprint('pip show kedro output:\u001b[39m\n          ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated string literal (detected at line 15)\n"
     ]
    }
   ],
   "source": [
    "# 1) Configurar entorno y dependencias\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "import traceback\n",
    "from pathlib import Path\n",
    "# -- Diagnostic prints: which Python/kernel is executing this notebook?\n",
    "print('Notebook Python executable:', sys.executable)\n",
    "print('First entries in sys.path:', sys.path[:6])\n",
    "# Check if kedro is visible to this interpreter\n",
    "import subprocess\n",
    "try:\n",
    "    res = subprocess.run([sys.executable, '-m', 'pip', 'show', 'kedro'], capture_output=True, text=True)\n",
    "    print('pip show kedro output:\n",
    "except Exception as exc:\n",
    "    print('Failed to run pip show kedro:', exc)\n",
    "\n",
    "# Detectar automáticamente la raíz del proyecto: busca un padre que contenga 'src', 'pyproject.toml' o 'conf'\n",
    "def find_project_root(start=Path.cwd()):\n",
    "    cur = Path(start).resolve()\n",
    "    for parent in [cur] + list(cur.parents):\n",
    "        if (parent / 'src').is_dir() or (parent / 'pyproject.toml').is_file() or (parent / 'conf').is_dir():\n",
    "            return parent\n",
    "    # Si no encuentra nada, usa el directorio actual (útil si ejecutas desde la raíz manualmente)\n",
    "    return Path.cwd()\n",
    "ROOT = find_project_root()\n",
    "print(\"Project root (detected):\", ROOT)\n",
    "\n",
    "# Añadir src al path para poder importar el paquete covid19df\n",
    "sys.path.insert(0, str(ROOT / \"src\"))\n",
    "\n",
    "# Rutas de entrada/salida\n",
    "INPUT_CSV = str(ROOT / \"data\" / \"03_intermediate\" / \"covid_19_clean_complete_CLEAN.csv\")\n",
    "OUT_DIR = str(ROOT / \"data\" / \"05_train\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# Archivos de salida recomendados\n",
    "ELBOW_CSV = os.path.join(OUT_DIR, \"elbow.csv\")\n",
    "ELBOW_PLOT = os.path.join(OUT_DIR, \"elbow.png\")\n",
    "KMEANS_CSV = os.path.join(OUT_DIR, \"kmeans_clusters.csv\")\n",
    "KMEANS_METRICS = os.path.join(OUT_DIR, \"kmeans_metrics.csv\")\n",
    "DBSCAN_CSV = os.path.join(OUT_DIR, \"dbscan_clusters.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Input CSV exists:\", os.path.exists(INPUT_CSV))TSNE_SCATTER = os.path.join(OUT_DIR, \"tsne_scatter.png\")PCA_SCATTER = os.path.join(OUT_DIR, \"pca_scatter.png\")TSNE_EMB = os.path.join(OUT_DIR, \"tsne_embeddings.csv\")PCA_EMB = os.path.join(OUT_DIR, \"pca_embeddings.csv\")DENDRO_PLOT = os.path.join(OUT_DIR, \"dendrogram.png\")HIER_METRICS = os.path.join(OUT_DIR, \"hier_metrics.csv\")HIER_CSV = os.path.join(OUT_DIR, \"hier_clusters.csv\")DBSCAN_METRICS = os.path.join(OUT_DIR, \"dbscan_metrics.csv\")print(\"Input CSV exists:\", os.path.exists(INPUT_CSV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88c5da83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kedro no disponible en este entorno: No module named 'kedro'\n"
     ]
    }
   ],
   "source": [
    "# 2) Inicializar contexto Kedro desde el notebook (ejemplo)\n",
    "\n",
    "try:\n",
    "    from kedro.framework.session import KedroSession\n",
    "    from kedro.config import ConfigLoader\n",
    "    print(\"Kedro imports OK\")\n",
    "except Exception as exc:\n",
    "    print(\"Kedro no disponible en este entorno:\", exc)\n",
    "    # No fallamos; muchas acciones del notebook se hacen directamente con las funciones\n",
    "\n",
    "# Ejemplo de cómo crear una sesión (comentar si no quieres ejecutar dentro del notebook)\n",
    "# from kedro.framework.session import KedroSession\n",
    "# with KedroSession.create() as session:\n",
    "#     context = session.load_context()\n",
    "#     print(type(context))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf08c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al importar/ejecutar register_pipelines:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hansi\\AppData\\Local\\Temp\\ipykernel_9912\\106485718.py\", line 4, in <module>\n",
      "    from covid19df import pipeline_registry as pr\n",
      "  File \"C:\\Users\\hansi\\Desktop\\kedro\\covid19DF_Ev02\\covid19df\\src\\covid19df\\pipeline_registry.py\", line 1, in <module>\n",
      "    from covid19df.pipelines import eda as eda_pipeline\n",
      "  File \"C:\\Users\\hansi\\Desktop\\kedro\\covid19DF_Ev02\\covid19df\\src\\covid19df\\pipelines\\eda\\__init__.py\", line 6, in <module>\n",
      "    from .pipeline import create_pipeline\n",
      "  File \"C:\\Users\\hansi\\Desktop\\kedro\\covid19DF_Ev02\\covid19df\\src\\covid19df\\pipelines\\eda\\pipeline.py\", line 7, in <module>\n",
      "    from kedro.pipeline import Pipeline, node\n",
      "ModuleNotFoundError: No module named 'kedro'\n"
     ]
    }
   ],
   "source": [
    "# 3) Cargar y listar pipelines registrados\n",
    "\n",
    "try:\n",
    "    from covid19df import pipeline_registry as pr\n",
    "    pipelines = pr.register_pipelines()\n",
    "    print(\"Registered pipelines:\", list(pipelines.keys()))\n",
    "    cur = Path.cwd().resolve()\n",
    "    for parent in [cur] + list(cur.parents):\n",
    "        if (parent / 'src').is_dir():\n",
    "            p = str((parent / 'src').resolve())\n",
    "            if p not in sys.path:\n",
    "                sys.path.insert(0, p)\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "try:\n",
    "    from covid19df import pipeline_registry as pr\n",
    "    pipelines = pr.register_pipelines()\n",
    "    print(\"Registered pipelines:\", list(pipelines.keys()))\n",
    "    # Mostrar número de nodos en cada pipeline si tiene el método 'nodes' o similar\n",
    "    for name, p in pipelines.items():\n",
    "        try:\n",
    "            nodes = getattr(p, 'nodes', None)\n",
    "            if nodes is not None:\n",
    "                print(f\"- {name}: {len(nodes)} nodes\")\n",
    "        except Exception:\n",
    "            pass\n",
    "except Exception:\n",
    "    print(\"Error al importar/ejecutar register_pipelines (first attempt):\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    # Intentar corregir sys.path y reintentar una vez\n",
    "    if ensure_src_on_path():\n",
    "        try:\n",
    "            from covid19df import pipeline_registry as pr\n",
    "            pipelines = pr.register_pipelines()\n",
    "            print(\"Registered pipelines after fixing sys.path:\", list(pipelines.keys()))\n",
    "        except Exception:\n",
    "            print(\"Retry failed. Traceback:\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8735f4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se pudo ejecutar KedroSession.run - puedes ejecutar Kedro desde terminal:\n",
      "  kedro run --pipeline eda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hansi\\AppData\\Local\\Temp\\ipykernel_9912\\2877589214.py\", line 4, in <module>\n",
      "    from kedro.framework.session import KedroSession\n",
      "ModuleNotFoundError: No module named 'kedro'\n"
     ]
    }
   ],
   "source": [
    "# 4) Ejecutar pipeline 'eda' (modo interactivo) — ejemplo con KedroSession (si está disponible)\n",
    "\n",
    "try:\n",
    "    from kedro.framework.session import KedroSession\n",
    "    print('Using KedroSession to run pipeline \"eda\" (this may take some time)')\n",
    "    with KedroSession.create() as session:\n",
    "        session.run(pipeline_name='eda')\n",
    "    print('Finished running pipeline eda')\n",
    "except Exception as exc:\n",
    "    print('No se pudo ejecutar KedroSession.run - puedes ejecutar Kedro desde terminal:')\n",
    "    print('  kedro run --pipeline eda')\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f7c7096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si KedroSession falla, ejecuta en terminal:\n",
      "  kedro run --pipeline regresion\n",
      "  kedro run --pipeline clasificacion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hansi\\AppData\\Local\\Temp\\ipykernel_9912\\2424806158.py\", line 4, in <module>\n",
      "    from kedro.framework.session import KedroSession\n",
      "ModuleNotFoundError: No module named 'kedro'\n"
     ]
    }
   ],
   "source": [
    "# 5) Ejecutar pipelines 'regresion' y 'clasificacion' — ejemplo\n",
    "\n",
    "try:\n",
    "    from kedro.framework.session import KedroSession\n",
    "    print('Running regresion and clasificacion via KedroSession')\n",
    "    with KedroSession.create() as session:\n",
    "        session.run(pipeline_name='regresion')\n",
    "        session.run(pipeline_name='clasificacion')\n",
    "    print('Finished running regresion and clasificacion')\n",
    "except Exception:\n",
    "    print('Si KedroSession falla, ejecuta en terminal:')\n",
    "    print('  kedro run --pipeline regresion')\n",
    "    print('  kedro run --pipeline clasificacion')\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcaede6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Manejar import errors y mostrar traceback (ejemplo de import perezoso)\n",
    "\n",
    "try:\n",
    "    # Forzar una importación perezosa similar a pipeline_registry\n",
    "    import importlib\n",
    "    importlib.import_module('covid19df.pipelines.unsupervised.clustering.pipeline')\n",
    "    print('Clustering pipeline module imported OK')\n",
    "except Exception:\n",
    "    print('Import error detected: show full traceback')\n",
    "    traceback.print_exc()\n",
    "    print('\\nRevisa los errores anteriores, suelen implicar dependencias faltantes o errores de sintaxis en los módulos.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12374c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Guardar y visualizar artefactos/resultados (ejemplo ad-hoc ejecutando funciones directamente)\n",
    "\n",
    "# Importar funciones de los nodos que creamos para ejecución ad-hoc\n",
    "from covid19df.pipelines.unsupervised.clustering.nodes import (\n",
    "    load_latest_by_country, preprocess_for_clustering, elbow_method,\n",
    "    run_kmeans, run_dbscan, run_hierarchical, compute_clustering_metrics,\n",
    "    save_cluster_results, plot_dendrogram, save_metrics_csv\n",
    ")\n",
    "from covid19df.pipelines.unsupervised.reduction.nodes import run_pca, run_tsne, save_embeddings\n",
    "\n",
    "# Cargar y preprocesar\n",
    "raw = load_latest_by_country(INPUT_CSV)\n",
    "X_scaled_df, raw_df = preprocess_for_clustering(raw)\n",
    "print('Data loaded:', raw_df.shape, 'Features:', X_scaled_df.shape)\n",
    "\n",
    "# Elbow\n",
    "elbow_res = elbow_method(X_scaled_df, k_min=2, k_max=8, out_csv=ELBOW_CSV, out_plot=ELBOW_PLOT)\n",
    "print('Elbow saved to', ELBOW_CSV, ELBOW_PLOT)\n",
    "\n",
    "# KMeans\n",
    "k = 4\n",
    "k_labels, k_model = run_kmeans(X_scaled_df, n_clusters=k)\n",
    "save_cluster_results(raw_df, k_labels, KMEANS_CSV)\n",
    "k_metrics = compute_clustering_metrics(X_scaled_df, k_labels)\n",
    "save_metrics_csv(k_metrics, KMEANS_METRICS)\n",
    "print('KMeans saved:', KMEANS_CSV, KMEANS_METRICS)\n",
    "\n",
    "# DBSCAN\n",
    "db_labels, db_model = run_dbscan(X_scaled_df, eps=0.5, min_samples=5)\n",
    "save_cluster_results(raw_df, db_labels, DBSCAN_CSV)\n",
    "db_metrics = compute_clustering_metrics(X_scaled_df, db_labels)\n",
    "save_metrics_csv(db_metrics, DBSCAN_METRICS)\n",
    "print('DBSCAN saved:', DBSCAN_CSV, DBSCAN_METRICS)\n",
    "\n",
    "# Hierarchical\n",
    "h_labels, h_model = run_hierarchical(X_scaled_df, n_clusters=k)\n",
    "save_cluster_results(raw_df, h_labels, HIER_CSV)\n",
    "h_metrics = compute_clustering_metrics(X_scaled_df, h_labels)\n",
    "save_metrics_csv(h_metrics, HIER_METRICS)\n",
    "print('Hierarchical saved:', HIER_CSV, HIER_METRICS)\n",
    "\n",
    "# Dendrogram\n",
    "dendro = plot_dendrogram(X_scaled_df, method='ward', out_plot=DENDRO_PLOT)\n",
    "print('Dendrogram saved:', DENDRO_PLOT if dendro else 'not generated')\n",
    "\n",
    "# PCA + t-SNE\n",
    "pca_res = run_pca(X_scaled_df, n_components=2)\n",
    "import numpy as np\n",
    "save_embeddings(raw_df, np.array(pca_res['embeddings']), PCA_EMB)\n",
    "print('PCA embeddings saved:', PCA_EMB)\n",
    "\n",
    "try:\n",
    "    tsne_res = run_tsne(X_scaled_df, n_components=2, perplexity=30.0)\n",
    "    save_embeddings(raw_df, np.array(tsne_res['embeddings']), TSNE_EMB)\n",
    "    print('t-SNE embeddings saved:', TSNE_EMB)\n",
    "except Exception:\n",
    "    print('t-SNE failed (can be slow); skip tsne embedding')\n",
    "\n",
    "# Visualizar scatter de PCA con etiquetas KMeans (si matplotlib disponible)\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    emb = np.array(pca_res['embeddings'])\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.scatterplot(x=emb[:,0], y=emb[:,1], hue=k_labels, palette='tab10', s=40)\n",
    "    plt.title('PCA scatter colored by KMeans')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(PCA_SCATTER)\n",
    "    plt.close()\n",
    "    print('PCA scatter saved:', PCA_SCATTER)\n",
    "except Exception:\n",
    "    print('matplotlib/seaborn not available; skipping scatter plot')\n",
    "\n",
    "try:\n",
    "    if os.path.exists(TSNE_EMB):\n",
    "        emb2 = np.loadtxt(TSNE_EMB, delimiter=',', skiprows=1)[:,1:3] if False else None\n",
    "except Exception:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c3ddab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Ejecutar tests unitarios desde el notebook (ejemplo)\n",
    "\n",
    "# Puedes ejecutar pytest desde el notebook usando una celda bash o subprocess\n",
    "print('Running pytest -k eda (example). This runs in a subprocess and prints output below:')\n",
    "\n",
    "import subprocess\n",
    "try:\n",
    "    res = subprocess.run([sys.executable, '-m', 'pytest', '-q'], capture_output=True, text=True)\n",
    "    print(res.stdout)\n",
    "    if res.returncode != 0:\n",
    "        print('Some tests failed. See above output.')\n",
    "except Exception as exc:\n",
    "    print('Unable to run pytest from notebook:', exc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4159dc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Reproducibilidad: fijar seed y mostrar versiones\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Mostrar versiones\n",
    "import platform\n",
    "import pkgutil\n",
    "print('Python:', platform.python_version())\n",
    "for pkg in ('kedro','pandas','numpy','scikit_learn','matplotlib','scipy','seaborn'):\n",
    "    try:\n",
    "        loader = pkgutil.find_loader(pkg)\n",
    "        print(pkg, 'installed:', loader is not None)\n",
    "    except Exception:\n",
    "        print(pkg, 'check failed')\n",
    "\n",
    "print('\\nDone. The notebook saved outputs to', OUT_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
